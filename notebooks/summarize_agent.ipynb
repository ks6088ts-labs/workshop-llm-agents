{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8282437f-cc19-4c53-97d5-5b7f12986cfd",
   "metadata": {},
   "source": [
    "# Summarize Agent\n",
    "\n",
    "- [summarize_agent.py](https://github.com/ks6088ts-labs/workshop-llm-agents/blob/main/workshop_llm_agents/agents/summarize_agent.py)\n",
    "\n",
    "## References\n",
    "\n",
    "- [How to summarize text through parallelization](https://python.langchain.com/docs/how_to/summarize_map_reduce/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf88711-0351-4cd5-bdee-b6651b0125bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8406cfd0-0a40-44da-9686-2ac289231344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "assert load_dotenv(override=True), \"Failed to load .env file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52fd18b-23e2-4a38-b55d-a3eb4fb51b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up LLM\n",
    "from workshop_llm_agents.llms.azure_openai import AzureOpenAIWrapper\n",
    "\n",
    "azure_openai_wrapper = AzureOpenAIWrapper()\n",
    "llm = azure_openai_wrapper.get_azure_chat_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17d8f44b-c476-4886-b2f3-376b4ccb51dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# Load documents\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "web_path = \"https://learn.microsoft.com/ja-jp/azure/ai-services/openai/overview\"\n",
    "loader = WebBaseLoader(\n",
    "    web_path=web_path,\n",
    "    header_template={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36\",  # noqa: E501\n",
    "    },\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076dca19-5903-4d8e-ac23-fea6c737f2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of chunks: 3\n"
     ]
    }
   ],
   "source": [
    "# Split into chunks\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "print(f\"# of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eebb68c-3e67-49ca-963f-7121005ace18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent\n",
    "from workshop_llm_agents.agents.summarize_agent import SummarizeAgent\n",
    "\n",
    "agent = SummarizeAgent(\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae25fe73-eded-4399-b5ce-1892acfb1761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump an image of agent graph\n",
    "png = \"../docs/images/summarize_agent.png\"\n",
    "with open(png, \"wb\") as f:\n",
    "    f.write(agent.mermaid_png(output_file_path=png))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4858868-3052-439a-ae75-dcb044f03be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['generate_summary']\n",
      "['collect_summaries']\n",
      "['generate_final_summary']\n",
      "final output: The Azure OpenAI Service is a comprehensive platform that provides access to OpenAI's advanced language models, such as GPT-4o, GPT-4 Turbo with Vision, and GPT-3.5-Turbo, through REST API, Python SDK, and Azure AI Foundry. These models can be fine-tuned for tasks like content generation, summarization, image interpretation, and code translation. The service emphasizes responsible AI use with content filtering and ethical guidelines. Users must create an Azure OpenAI Service resource to deploy models and can utilize features like real-time audio and assistant capabilities. The service integrates OpenAI models with Azure's security features, supporting virtual networks and managed identities. Text and image processing involve tokenization, with costs varying by detail and size. Additionally, the service offers models like DALL-E for image generation and Whisper for speech-to-text. The document also briefly mentions the California Consumer Privacy Act (CCPA) opt-out icon, highlighting privacy choices and related themes.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "response = await agent.run(docs=chunks)\n",
    "print(f\"final output: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d374475-774b-4cfa-99e7-6b50e5cdafb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
