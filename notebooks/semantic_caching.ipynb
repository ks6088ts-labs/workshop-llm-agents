{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d2702d-da6d-413a-a4f8-8d96adf443c0",
   "metadata": {},
   "source": [
    "- [Optimize Azure OpenAI Applications with Semantic Caching](https://techcommunity.microsoft.com/blog/azurearchitectureblog/optimize-azure-openai-applications-with-semantic-caching/4106867)\n",
    "- [How to cache chat model responses](https://python.langchain.com/docs/how_to/chat_model_caching/)\n",
    "- [Tutorial: Use Azure Cache for Redis as a semantic cache\n",
    "](https://learn.microsoft.com/en-us/azure/azure-cache-for-redis/cache-tutorial-semantic-cache)\n",
    "- [Enable semantic caching for Azure OpenAI APIs in Azure API Management](https://learn.microsoft.com/en-us/azure/api-management/azure-openai-enable-semantic-caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cecd5da8-f8c6-4bd6-beca-2c294909c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c843e0fe-31ed-4321-a892-57739e37f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "assert load_dotenv(override=True), \"Failed to load .env file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38fb74d-f7ec-403e-a62b-8b96aeab9bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/home/stakenaka/src/github.com/ks6088ts-labs/workshop-llm-agents/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='/home/stakenaka/src/github.com/ks6088ts-labs/workshop-llm-agents/.venv/lib/python3.10/site-packages/certifi/cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "# Set up LLM\n",
    "from workshop_llm_agents.llms.azure_openai import AzureOpenAIWrapper\n",
    "\n",
    "azure_openai_wrapper = AzureOpenAIWrapper()\n",
    "llm = azure_openai_wrapper.get_azure_chat_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60e73de3-a9ea-4504-a46f-78ed8c6ad8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.caches import InMemoryCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9bad5ca-1297-436f-a9ea-c350040ad7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/deployments/gpt-4o/chat/completions', 'headers': {'api-key': '<redacted>'}, 'files': None, 'json_data': {'messages': [{'content': 'Tell me a joke', 'role': 'user'}], 'model': 'gpt-4o', 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://aoaiplaygroundsnih8leastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-10-21\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='aoaiplaygroundsnih8leastus.openai.azure.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f47f8fa3400>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x7f47f91d6fc0> server_hostname='aoaiplaygroundsnih8leastus.openai.azure.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f47f8fa32b0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'1176'), (b'Content-Type', b'application/json'), (b'apim-request-id', b'05ee86a2-2d2d-4f07-b414-0754fa554f0e'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'x-content-type-options', b'nosniff'), (b'x-ms-region', b'East US'), (b'x-ratelimit-remaining-requests', b'449'), (b'x-ratelimit-limit-requests', b'450'), (b'x-ratelimit-remaining-tokens', b'449356'), (b'x-ratelimit-limit-tokens', b'450000'), (b'cmp-upstream-response-duration', b'350'), (b'x-accel-buffering', b'no'), (b'x-aml-cluster', b'hyena-japaneast-02'), (b'x-envoy-upstream-service-time', b'401'), (b'x-ms-rai-invoked', b'true'), (b'x-request-id', b'43a37d83-82f6-4f0d-a85d-d9c5bf0cd81c'), (b'ms-azureml-model-time', b'396'), (b'x-ms-client-request-id', b'05ee86a2-2d2d-4f07-b414-0754fa554f0e'), (b'azureml-model-session', b'v20250225-1-161802030'), (b'Date', b'Wed, 19 Mar 2025 04:13:13 GMT')])\n",
      "INFO:httpx:HTTP Request: POST https://aoaiplaygroundsnih8leastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-10-21 \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://aoaiplaygroundsnih8leastus.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-10-21 \"200 OK\" Headers({'content-length': '1176', 'content-type': 'application/json', 'apim-request-id': '05ee86a2-2d2d-4f07-b414-0754fa554f0e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'x-ms-region': 'East US', 'x-ratelimit-remaining-requests': '449', 'x-ratelimit-limit-requests': '450', 'x-ratelimit-remaining-tokens': '449356', 'x-ratelimit-limit-tokens': '450000', 'cmp-upstream-response-duration': '350', 'x-accel-buffering': 'no', 'x-aml-cluster': 'hyena-japaneast-02', 'x-envoy-upstream-service-time': '401', 'x-ms-rai-invoked': 'true', 'x-request-id': '43a37d83-82f6-4f0d-a85d-d9c5bf0cd81c', 'ms-azureml-model-time': '396', 'x-ms-client-request-id': '05ee86a2-2d2d-4f07-b414-0754fa554f0e', 'azureml-model-session': 'v20250225-1-161802030', 'date': 'Wed, 19 Mar 2025 04:13:13 GMT'})\n",
      "DEBUG:openai._base_client:request_id: 43a37d83-82f6-4f0d-a85d-d9c5bf0cd81c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 110 ms, sys: 733 Î¼s, total: 111 ms\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "response = llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7323adb-af60-4bf4-8099-4a1df43c0b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 651 Î¼s, sys: 50 Î¼s, total: 701 Î¼s\n",
      "Wall time: 692 Î¼s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure! Here's one for you:\\n\\nWhy donâ€™t skeletons fight each other?\\n\\nBecause they donâ€™t have the guts! ðŸ˜„\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 11, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ded0d14823', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}, id='run-709d0bb4-7f18-4f4c-8b20-cdcc11ef26bc-0', usage_metadata={'input_tokens': 11, 'output_tokens': 27, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace946c3-e29b-4f36-a104-80efaa972ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
